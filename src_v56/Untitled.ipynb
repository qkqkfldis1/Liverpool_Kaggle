{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/25/2020, 13:33:03 ##################### Start ... ##################### \n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Much of this comes from https://www.kaggle.com/pradeeppathak9/gamma-log-facies-type-prediction\n",
    "# https://www.crowdanalytix.com/contests/gamma-log-facies-type-prediction\n",
    "######################################################\n",
    "import os\n",
    "#os.system('pip install pytorch_toolbelt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby, accumulate\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # specify which GPU(s) to be used\n",
    "\n",
    "log = Logger()\n",
    "log.open(f'./log.seq2seq-rnn-with-gru_noise.txt', mode='w')\n",
    "date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "log.write(f\"{date_time} ##################### Start ... ##################### \\n\")\n",
    "\n",
    "\n",
    "ss = pd.read_csv(\"/home/lyh/liverpool/sample_submission.csv\", dtype={'time':str})\n",
    "train = pd.read_csv('/home/lyh/liverpool/train_clean.csv')\n",
    "train['filter'] = 0\n",
    "test = pd.read_csv('/home/lyh/liverpool/test_clean.csv')\n",
    "test['filter'] = 2\n",
    "\n",
    "Y_train_proba = np.load(\"/home/lyh/liverpool/Y_train_proba.npy\")\n",
    "Y_test_proba = np.load(\"/home/lyh/liverpool/Y_test_proba.npy\")\n",
    "\n",
    "for i in range(11):\n",
    "    train[f\"proba_{i}\"] = Y_train_proba[:, i]\n",
    "    test[f\"proba_{i}\"] = Y_test_proba[:, i]\n",
    "    \n",
    "STD = 0.01\n",
    "old_data = train['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(train))\n",
    "train['signal_noised'] = new_data\n",
    "\n",
    "old_data = test['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(test))\n",
    "test['signal_noised'] = new_data\n",
    "\n",
    "\n",
    "STD = 0.001\n",
    "old_data = train['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(train))\n",
    "train['signal_noised'] = new_data\n",
    "\n",
    "old_data = test['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(test))\n",
    "test['signal_noised'] = new_data\n",
    "\n",
    "\n",
    "STD = 0.1\n",
    "old_data = train['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(train))\n",
    "train['signal_noised'] = new_data\n",
    "\n",
    "old_data = test['signal']\n",
    "new_data = old_data + np.random.normal(0, STD, size=len(test))\n",
    "test['signal_noised'] = new_data\n",
    "    \n",
    "ts1 = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\n",
    "\n",
    "ts1['time2'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14 + 1), labels=list(range(14)), include_lowest=True).astype(int)\n",
    "ts1['time2'] = ts1.groupby('time2')['time'].rank( )/500000.\n",
    "\n",
    "np.random.seed(321)\n",
    "ts1['group'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14*125 + 1), labels=list(range(14*125)), include_lowest=True).astype(int)\n",
    "np.random.seed(321)\n",
    "\n",
    "y = ts1.loc[ts1['filter']==0, 'open_channels']\n",
    "group = ts1.loc[ts1['filter']==0, 'group']\n",
    "X = ts1.loc[ts1['filter']==0, 'signal']\n",
    "\n",
    "np.random.seed(321)\n",
    "skf = GroupKFold(n_splits=5)\n",
    "splits = [x for x in skf.split(X, y, group)]\n",
    "\n",
    "use_cols = [col for col in ts1.columns if col not in ['index','filter','group', 'open_channels', 'time', 'time2']]  \n",
    "\n",
    "# Create numpy array of inputs\n",
    "for col in use_cols:\n",
    "    col_mean = ts1[col].mean()\n",
    "    ts1[col] = ts1[col].fillna(col_mean)\n",
    " \n",
    "\n",
    "val_preds_all = np.zeros((ts1[ts1['filter']==0].shape[0], 11))\n",
    "test_preds_all = np.zeros((ts1[ts1['filter']==2].shape[0], 11))\n",
    "\n",
    "groups = ts1.loc[ts1['filter']==0, 'group']\n",
    "times = ts1.loc[ts1['filter']==0, 'time']\n",
    "\n",
    "new_splits = []\n",
    "for sp in splits:\n",
    "    new_split = []\n",
    "    new_split.append(np.unique(groups[sp[0]]))\n",
    "    new_split.append(np.unique(groups[sp[1]]))\n",
    "    new_splits.append(new_split)\n",
    "    \n",
    "trainval = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "test = np.array(list(ts1[ts1['filter']==2].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "trainval_y = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[['open_channels']].values)))\n",
    "\n",
    "gc.collect()\n",
    "# transpose to B x C x L\n",
    "trainval = trainval.transpose((0,2,1))\n",
    "test = test.transpose((0,2,1))\n",
    "\n",
    "trainval_y = trainval_y.reshape(trainval_y.shape[:2])\n",
    "test_y = np.zeros((test.shape[0], trainval_y.shape[1]))\n",
    "\n",
    "trainval = torch.Tensor(trainval)\n",
    "test = torch.Tensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 13, 4000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 13, 4000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 9., 10.,  9., ...,  9.,  9.,  8.],\n",
       "       [ 8.,  9.,  9., ...,  7.,  7.,  8.],\n",
       "       [ 6.,  7.,  8., ...,  8.,  9.,  9.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([   0,    1,    3,    4,    5,    6,    8,    9,   10,   11,   13,\n",
       "           14,   15,   16,   17,   18,   20,   22,   23,   24,   25,   27,\n",
       "           28,   29,   30,   32,   33,   34,   35,   36,   37,   39,   40,\n",
       "           41,   43,   44,   45,   46,   48,   49,   50,   51,   53,   54,\n",
       "           55,   56,   58,   59,   60,   62,   63,   64,   65,   66,   68,\n",
       "           69,   70,   72,   73,   74,   75,   76,   77,   80,   81,   82,\n",
       "           83,   85,   86,   87,   88,   90,   91,   92,   93,   95,   96,\n",
       "           97,   98,  100,  101,  102,  103,  105,  106,  107,  108,  110,\n",
       "          111,  112,  113,  115,  116,  117,  118,  120,  121,  122,  123,\n",
       "          125,  126,  127,  128,  130,  131,  132,  133,  134,  135,  136,\n",
       "          137,  139,  140,  141,  142,  144,  145,  146,  147,  149,  150,\n",
       "          151,  152,  154,  155,  157,  159,  160,  161,  162,  164,  165,\n",
       "          166,  167,  169,  170,  171,  172,  173,  174,  175,  176,  178,\n",
       "          179,  180,  181,  183,  184,  185,  186,  188,  189,  190,  191,\n",
       "          194,  195,  196,  197,  199,  200,  201,  202,  204,  205,  206,\n",
       "          207,  209,  210,  211,  212,  213,  214,  216,  218,  219,  220,\n",
       "          221,  223,  224,  225,  226,  228,  229,  230,  231,  232,  233,\n",
       "          234,  235,  236,  237,  238,  240,  241,  242,  243,  245,  246,\n",
       "          247,  248,  250,  251,  253,  254,  255,  256,  257,  259,  260,\n",
       "          261,  262,  263,  264,  265,  266,  267,  269,  270,  271,  273,\n",
       "          274,  275,  276,  277,  278,  280,  281,  282,  283,  285,  286,\n",
       "          287,  288,  291,  292,  293,  294,  295,  296,  297,  299,  300,\n",
       "          302,  304,  305,  306,  307,  309,  310,  311,  313,  314,  315,\n",
       "          316,  317,  319,  320,  321,  322,  324,  325,  326,  327,  330,\n",
       "          331,  332,  333,  334,  335,  336,  338,  339,  341,  343,  344,\n",
       "          345,  346,  348,  349,  350,  351,  352,  354,  355,  356,  357,\n",
       "          359,  360,  361,  362,  364,  365,  366,  367,  368,  369,  370,\n",
       "          371,  373,  374,  375,  376,  378,  379,  380,  381,  383,  384,\n",
       "          385,  386,  388,  389,  390,  391,  392,  393,  394,  396,  397,\n",
       "          398,  399,  400,  401,  402,  403,  404,  406,  407,  409,  411,\n",
       "          412,  413,  414,  416,  417,  418,  419,  420,  421,  422,  423,\n",
       "          424,  426,  427,  428,  429,  432,  433,  434,  436,  437,  438,\n",
       "          439,  441,  442,  443,  444,  446,  447,  449,  450,  451,  452,\n",
       "          453,  455,  456,  457,  458,  459,  460,  461,  462,  463,  465,\n",
       "          466,  468,  469,  471,  472,  473,  475,  476,  477,  478,  480,\n",
       "          481,  482,  483,  485,  486,  488,  489,  490,  491,  492,  494,\n",
       "          495,  496,  497,  498,  499,  500,  501,  502,  504,  505,  506,\n",
       "          508,  509,  510,  511,  512,  513,  515,  516,  517,  518,  520,\n",
       "          521,  522,  523,  526,  527,  528,  529,  530,  531,  532,  534,\n",
       "          535,  537,  539,  540,  541,  542,  544,  545,  546,  547,  548,\n",
       "          549,  551,  552,  553,  554,  556,  557,  558,  559,  561,  562,\n",
       "          563,  564,  565,  566,  568,  570,  571,  572,  573,  575,  576,\n",
       "          577,  578,  580,  581,  582,  583,  584,  585,  587,  588,  589,\n",
       "          591,  592,  593,  594,  596,  597,  598,  599,  601,  602,  603,\n",
       "          604,  606,  607,  608,  610,  611,  612,  613,  614,  616,  617,\n",
       "          618,  620,  621,  622,  623,  625,  626,  627,  629,  630,  631,\n",
       "          632,  634,  635,  636,  637,  639,  640,  641,  642,  643,  644,\n",
       "          646,  648,  649,  650,  651,  653,  654,  655,  656,  658,  659,\n",
       "          660,  661,  662,  663,  665,  666,  667,  669,  670,  671,  672,\n",
       "          674,  675,  676,  677,  679,  680,  681,  682,  684,  685,  686,\n",
       "          688,  689,  690,  691,  692,  694,  695,  696,  698,  699,  700,\n",
       "          701,  702,  703,  705,  706,  707,  708,  710,  711,  712,  713,\n",
       "          715,  716,  717,  718,  721,  722,  723,  724,  725,  726,  727,\n",
       "          729,  730,  732,  734,  735,  736,  737,  739,  740,  741,  742,\n",
       "          743,  745,  746,  747,  748,  750,  751,  752,  753,  755,  756,\n",
       "          757,  758,  759,  760,  761,  762,  764,  765,  766,  767,  769,\n",
       "          770,  771,  772,  774,  775,  776,  777,  779,  780,  781,  782,\n",
       "          784,  785,  786,  787,  789,  790,  791,  792,  794,  795,  796,\n",
       "          797,  798,  799,  800,  801,  803,  804,  805,  806,  808,  809,\n",
       "          810,  811,  813,  814,  815,  816,  819,  820,  821,  822,  824,\n",
       "          825,  826,  827,  829,  830,  831,  832,  834,  835,  836,  837,\n",
       "          838,  839,  841,  843,  844,  845,  846,  848,  849,  850,  851,\n",
       "          853,  854,  855,  856,  857,  858,  859,  860,  861,  862,  863,\n",
       "          865,  866,  867,  868,  870,  871,  872,  873,  875,  876,  878,\n",
       "          879,  880,  881,  882,  884,  885,  886,  887,  888,  889,  890,\n",
       "          891,  892,  894,  895,  896,  898,  899,  900,  901,  902,  903,\n",
       "          905,  906,  907,  908,  910,  911,  912,  913,  916,  917,  918,\n",
       "          919,  920,  921,  922,  924,  925,  927,  929,  930,  931,  932,\n",
       "          934,  936,  937,  938,  939,  940,  941,  943,  944,  945,  946,\n",
       "          948,  949,  950,  951,  953,  954,  956,  957,  958,  959,  960,\n",
       "          962,  963,  964,  965,  966,  967,  968,  969,  970,  972,  973,\n",
       "          974,  976,  977,  978,  979,  980,  981,  983,  984,  985,  986,\n",
       "          988,  989,  990,  991,  994,  995,  996,  997,  998,  999, 1000,\n",
       "         1002, 1003, 1005, 1007, 1008, 1009, 1010, 1012, 1013, 1015, 1016,\n",
       "         1017, 1018, 1020, 1021, 1022, 1023, 1024, 1026, 1027, 1028, 1030,\n",
       "         1031, 1032, 1033, 1035, 1036, 1037, 1038, 1040, 1041, 1042, 1043,\n",
       "         1044, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1055, 1056, 1057,\n",
       "         1058, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1070, 1071,\n",
       "         1072, 1073, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1085,\n",
       "         1086, 1087, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097,\n",
       "         1099, 1100, 1101, 1102, 1104, 1105, 1106, 1107, 1109, 1110, 1111,\n",
       "         1112, 1114, 1115, 1116, 1118, 1119, 1120, 1121, 1122, 1124, 1125,\n",
       "         1126, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1136, 1137, 1139,\n",
       "         1140, 1141, 1142, 1144, 1145, 1146, 1147, 1149, 1150, 1152, 1153,\n",
       "         1154, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "         1166, 1168, 1169, 1172, 1173, 1175, 1176, 1177, 1178, 1180, 1181,\n",
       "         1182, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1194,\n",
       "         1195, 1196, 1197, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207,\n",
       "         1210, 1211, 1212, 1213, 1215, 1216, 1217, 1218, 1220, 1221, 1222,\n",
       "         1223, 1225, 1226, 1227, 1228, 1229, 1230, 1232, 1234, 1235, 1236,\n",
       "         1237, 1239, 1240, 1241, 1242, 1244, 1245, 1246, 1247, 1248]),\n",
       "  array([   2,    7,   12,   19,   21,   26,   31,   38,   42,   47,   52,\n",
       "           57,   61,   67,   71,   78,   79,   84,   89,   94,   99,  104,\n",
       "          109,  114,  119,  124,  129,  138,  143,  148,  153,  156,  158,\n",
       "          163,  168,  177,  182,  187,  192,  193,  198,  203,  208,  215,\n",
       "          217,  222,  227,  239,  244,  249,  252,  258,  268,  272,  279,\n",
       "          284,  289,  290,  298,  301,  303,  308,  312,  318,  323,  328,\n",
       "          329,  337,  340,  342,  347,  353,  358,  363,  372,  377,  382,\n",
       "          387,  395,  405,  408,  410,  415,  425,  430,  431,  435,  440,\n",
       "          445,  448,  454,  464,  467,  470,  474,  479,  484,  487,  493,\n",
       "          503,  507,  514,  519,  524,  525,  533,  536,  538,  543,  550,\n",
       "          555,  560,  567,  569,  574,  579,  586,  590,  595,  600,  605,\n",
       "          609,  615,  619,  624,  628,  633,  638,  645,  647,  652,  657,\n",
       "          664,  668,  673,  678,  683,  687,  693,  697,  704,  709,  714,\n",
       "          719,  720,  728,  731,  733,  738,  744,  749,  754,  763,  768,\n",
       "          773,  778,  783,  788,  793,  802,  807,  812,  817,  818,  823,\n",
       "          828,  833,  840,  842,  847,  852,  864,  869,  874,  877,  883,\n",
       "          893,  897,  904,  909,  914,  915,  923,  926,  928,  933,  935,\n",
       "          942,  947,  952,  955,  961,  971,  975,  982,  987,  992,  993,\n",
       "         1001, 1004, 1006, 1011, 1014, 1019, 1025, 1029, 1034, 1039, 1045,\n",
       "         1049, 1054, 1059, 1064, 1069, 1074, 1078, 1084, 1088, 1098, 1103,\n",
       "         1108, 1113, 1117, 1123, 1127, 1134, 1138, 1143, 1148, 1151, 1157,\n",
       "         1167, 1170, 1171, 1174, 1179, 1184, 1193, 1198, 1203, 1208, 1209,\n",
       "         1214, 1219, 1224, 1231, 1233, 1238, 1243, 1249])],\n",
       " [array([   0,    1,    2,    4,    5,    6,    7,    9,   10,   11,   12,\n",
       "           14,   15,   16,   17,   19,   20,   21,   23,   24,   25,   26,\n",
       "           27,   29,   30,   31,   33,   34,   35,   36,   37,   38,   40,\n",
       "           41,   42,   44,   45,   46,   47,   49,   50,   51,   52,   54,\n",
       "           55,   57,   58,   59,   60,   61,   63,   64,   65,   66,   67,\n",
       "           68,   69,   70,   71,   73,   74,   76,   78,   79,   81,   82,\n",
       "           83,   84,   86,   87,   88,   89,   91,   92,   93,   94,   95,\n",
       "           96,   97,   99,  101,  102,  103,  104,  106,  107,  108,  109,\n",
       "          111,  112,  113,  114,  116,  117,  118,  119,  121,  122,  123,\n",
       "          124,  126,  127,  128,  129,  131,  132,  133,  134,  135,  136,\n",
       "          138,  140,  141,  142,  143,  145,  146,  147,  148,  150,  151,\n",
       "          152,  153,  154,  155,  156,  157,  158,  160,  161,  162,  163,\n",
       "          165,  166,  167,  168,  170,  171,  172,  173,  174,  175,  177,\n",
       "          179,  180,  181,  182,  184,  185,  186,  187,  189,  190,  191,\n",
       "          192,  193,  194,  196,  197,  198,  200,  201,  202,  203,  205,\n",
       "          206,  207,  208,  210,  211,  212,  213,  215,  216,  217,  219,\n",
       "          220,  221,  222,  223,  225,  226,  227,  229,  230,  231,  232,\n",
       "          233,  234,  236,  237,  238,  239,  241,  242,  243,  244,  246,\n",
       "          247,  248,  249,  252,  253,  254,  255,  256,  257,  258,  260,\n",
       "          261,  263,  265,  266,  267,  268,  270,  271,  272,  273,  274,\n",
       "          276,  277,  278,  279,  281,  282,  283,  284,  286,  287,  288,\n",
       "          289,  290,  291,  292,  293,  295,  296,  297,  298,  300,  301,\n",
       "          302,  303,  305,  306,  307,  308,  310,  311,  312,  315,  316,\n",
       "          317,  318,  320,  321,  322,  323,  325,  326,  327,  328,  329,\n",
       "          330,  331,  332,  334,  335,  336,  337,  339,  340,  341,  342,\n",
       "          344,  345,  346,  347,  350,  351,  352,  353,  355,  356,  357,\n",
       "          358,  360,  361,  362,  363,  365,  366,  367,  368,  369,  370,\n",
       "          372,  374,  375,  376,  377,  379,  380,  381,  382,  384,  385,\n",
       "          386,  387,  388,  389,  390,  391,  392,  393,  394,  395,  397,\n",
       "          398,  400,  402,  403,  404,  405,  407,  408,  409,  410,  411,\n",
       "          412,  413,  414,  415,  417,  418,  420,  422,  423,  424,  425,\n",
       "          427,  428,  429,  430,  431,  432,  433,  434,  435,  437,  438,\n",
       "          439,  440,  442,  443,  444,  445,  448,  449,  450,  451,  452,\n",
       "          453,  454,  456,  457,  459,  461,  462,  463,  464,  466,  467,\n",
       "          469,  470,  471,  472,  473,  474,  476,  477,  478,  479,  481,\n",
       "          482,  483,  484,  487,  488,  489,  490,  491,  492,  493,  495,\n",
       "          496,  498,  500,  501,  502,  503,  505,  506,  507,  508,  509,\n",
       "          511,  512,  513,  514,  516,  517,  518,  519,  521,  522,  523,\n",
       "          524,  525,  526,  527,  528,  530,  531,  532,  533,  535,  536,\n",
       "          537,  538,  540,  541,  542,  543,  545,  546,  548,  549,  550,\n",
       "          552,  553,  554,  555,  557,  558,  559,  560,  562,  563,  564,\n",
       "          565,  567,  568,  569,  571,  572,  573,  574,  575,  577,  578,\n",
       "          579,  581,  582,  583,  584,  585,  586,  588,  589,  590,  592,\n",
       "          593,  594,  595,  597,  598,  599,  600,  602,  603,  605,  606,\n",
       "          607,  608,  609,  611,  612,  613,  614,  615,  616,  617,  618,\n",
       "          619,  621,  622,  623,  624,  627,  628,  630,  631,  632,  633,\n",
       "          635,  636,  637,  638,  640,  641,  642,  643,  645,  646,  647,\n",
       "          649,  650,  651,  652,  653,  655,  656,  657,  659,  660,  661,\n",
       "          662,  663,  664,  666,  667,  668,  670,  671,  672,  673,  675,\n",
       "          676,  677,  678,  680,  681,  683,  684,  685,  686,  687,  689,\n",
       "          690,  691,  692,  693,  694,  695,  696,  697,  699,  700,  703,\n",
       "          704,  706,  707,  708,  709,  711,  712,  713,  714,  716,  717,\n",
       "          718,  719,  720,  721,  722,  723,  725,  726,  727,  728,  730,\n",
       "          731,  732,  733,  735,  736,  737,  738,  741,  742,  743,  744,\n",
       "          746,  747,  748,  749,  751,  752,  753,  754,  756,  757,  758,\n",
       "          759,  760,  761,  763,  765,  766,  767,  768,  770,  771,  772,\n",
       "          773,  775,  776,  777,  778,  779,  780,  781,  782,  783,  785,\n",
       "          786,  787,  788,  790,  791,  792,  793,  795,  796,  797,  798,\n",
       "          799,  800,  802,  804,  805,  806,  807,  809,  810,  811,  812,\n",
       "          814,  815,  816,  817,  818,  819,  821,  822,  823,  825,  826,\n",
       "          827,  828,  830,  831,  832,  833,  835,  836,  837,  838,  840,\n",
       "          841,  842,  844,  845,  846,  847,  848,  850,  851,  852,  854,\n",
       "          855,  856,  857,  858,  859,  861,  862,  863,  864,  866,  867,\n",
       "          868,  869,  871,  872,  873,  874,  877,  878,  879,  880,  881,\n",
       "          882,  883,  885,  886,  888,  890,  891,  892,  893,  895,  896,\n",
       "          897,  898,  899,  901,  902,  903,  904,  906,  907,  908,  909,\n",
       "          911,  912,  913,  914,  915,  916,  917,  918,  920,  921,  922,\n",
       "          923,  925,  926,  927,  928,  930,  931,  932,  933,  935,  936,\n",
       "          937,  938,  939,  940,  941,  942,  944,  945,  946,  947,  949,\n",
       "          950,  951,  952,  955,  956,  957,  958,  959,  960,  961,  963,\n",
       "          964,  966,  968,  969,  970,  971,  973,  974,  975,  976,  977,\n",
       "          979,  980,  981,  982,  984,  985,  986,  987,  989,  990,  991,\n",
       "          992,  993,  994,  995,  996,  998,  999, 1000, 1001, 1003, 1004,\n",
       "         1005, 1006, 1008, 1009, 1010, 1011, 1013, 1014, 1015, 1016, 1017,\n",
       "         1018, 1019, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029,\n",
       "         1031, 1032, 1034, 1036, 1037, 1038, 1039, 1041, 1042, 1043, 1044,\n",
       "         1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1057, 1058,\n",
       "         1059, 1061, 1062, 1063, 1064, 1066, 1067, 1068, 1069, 1071, 1072,\n",
       "         1074, 1075, 1076, 1077, 1078, 1080, 1081, 1082, 1083, 1084, 1085,\n",
       "         1086, 1087, 1088, 1090, 1091, 1093, 1094, 1096, 1097, 1098, 1100,\n",
       "         1101, 1102, 1103, 1105, 1106, 1107, 1108, 1110, 1111, 1113, 1114,\n",
       "         1115, 1116, 1117, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126,\n",
       "         1127, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1140,\n",
       "         1141, 1142, 1143, 1145, 1146, 1147, 1148, 1151, 1152, 1153, 1154,\n",
       "         1155, 1156, 1157, 1159, 1160, 1162, 1164, 1165, 1166, 1167, 1169,\n",
       "         1170, 1171, 1172, 1173, 1174, 1176, 1177, 1178, 1179, 1181, 1182,\n",
       "         1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1193, 1195, 1196,\n",
       "         1197, 1198, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209,\n",
       "         1210, 1212, 1213, 1214, 1216, 1217, 1218, 1219, 1221, 1222, 1223,\n",
       "         1224, 1226, 1227, 1228, 1229, 1231, 1232, 1233, 1235, 1236, 1237,\n",
       "         1238, 1239, 1241, 1242, 1243, 1245, 1246, 1247, 1248, 1249]),\n",
       "  array([   3,    8,   13,   18,   22,   28,   32,   39,   43,   48,   53,\n",
       "           56,   62,   72,   75,   77,   80,   85,   90,   98,  100,  105,\n",
       "          110,  115,  120,  125,  130,  137,  139,  144,  149,  159,  164,\n",
       "          169,  176,  178,  183,  188,  195,  199,  204,  209,  214,  218,\n",
       "          224,  228,  235,  240,  245,  250,  251,  259,  262,  264,  269,\n",
       "          275,  280,  285,  294,  299,  304,  309,  313,  314,  319,  324,\n",
       "          333,  338,  343,  348,  349,  354,  359,  364,  371,  373,  378,\n",
       "          383,  396,  399,  401,  406,  416,  419,  421,  426,  436,  441,\n",
       "          446,  447,  455,  458,  460,  465,  468,  475,  480,  485,  486,\n",
       "          494,  497,  499,  504,  510,  515,  520,  529,  534,  539,  544,\n",
       "          547,  551,  556,  561,  566,  570,  576,  580,  587,  591,  596,\n",
       "          601,  604,  610,  620,  625,  626,  629,  634,  639,  644,  648,\n",
       "          654,  658,  665,  669,  674,  679,  682,  688,  698,  701,  702,\n",
       "          705,  710,  715,  724,  729,  734,  739,  740,  745,  750,  755,\n",
       "          762,  764,  769,  774,  784,  789,  794,  801,  803,  808,  813,\n",
       "          820,  824,  829,  834,  839,  843,  849,  853,  860,  865,  870,\n",
       "          875,  876,  884,  887,  889,  894,  900,  905,  910,  919,  924,\n",
       "          929,  934,  943,  948,  953,  954,  962,  965,  967,  972,  978,\n",
       "          983,  988,  997, 1002, 1007, 1012, 1020, 1030, 1033, 1035, 1040,\n",
       "         1050, 1055, 1056, 1060, 1065, 1070, 1073, 1079, 1089, 1092, 1095,\n",
       "         1099, 1104, 1109, 1112, 1118, 1128, 1132, 1139, 1144, 1149, 1150,\n",
       "         1158, 1161, 1163, 1168, 1175, 1180, 1185, 1192, 1194, 1199, 1204,\n",
       "         1211, 1215, 1220, 1225, 1230, 1234, 1240, 1244])],\n",
       " [array([   0,    1,    2,    3,    5,    6,    7,    8,   10,   11,   12,\n",
       "           13,   15,   16,   18,   19,   20,   21,   22,   24,   25,   26,\n",
       "           27,   28,   29,   30,   31,   32,   34,   35,   36,   38,   39,\n",
       "           40,   41,   42,   43,   45,   46,   47,   48,   50,   51,   52,\n",
       "           53,   56,   57,   58,   59,   60,   61,   62,   64,   65,   67,\n",
       "           69,   70,   71,   72,   74,   75,   77,   78,   79,   80,   82,\n",
       "           83,   84,   85,   86,   88,   89,   90,   92,   93,   94,   95,\n",
       "           97,   98,   99,  100,  102,  103,  104,  105,  106,  108,  109,\n",
       "          110,  112,  113,  114,  115,  117,  118,  119,  120,  122,  123,\n",
       "          124,  125,  127,  128,  129,  130,  132,  133,  134,  135,  137,\n",
       "          138,  139,  141,  142,  143,  144,  145,  147,  148,  149,  151,\n",
       "          152,  153,  154,  155,  156,  157,  158,  159,  161,  162,  163,\n",
       "          164,  166,  167,  168,  169,  171,  172,  173,  174,  176,  177,\n",
       "          178,  180,  181,  182,  183,  184,  186,  187,  188,  190,  191,\n",
       "          192,  193,  194,  195,  197,  198,  199,  201,  202,  203,  204,\n",
       "          206,  207,  208,  209,  211,  212,  214,  215,  216,  217,  218,\n",
       "          220,  221,  222,  223,  224,  225,  226,  227,  228,  230,  231,\n",
       "          234,  235,  237,  238,  239,  240,  242,  243,  244,  245,  247,\n",
       "          248,  249,  250,  251,  252,  253,  254,  256,  257,  258,  259,\n",
       "          261,  262,  263,  264,  266,  267,  268,  269,  272,  273,  274,\n",
       "          275,  277,  278,  279,  280,  282,  283,  284,  285,  287,  288,\n",
       "          289,  290,  291,  292,  294,  296,  297,  298,  299,  301,  302,\n",
       "          303,  304,  306,  307,  308,  309,  310,  312,  313,  314,  316,\n",
       "          317,  318,  319,  321,  322,  323,  324,  326,  327,  328,  329,\n",
       "          330,  331,  333,  335,  336,  337,  338,  340,  341,  342,  343,\n",
       "          345,  346,  347,  348,  349,  350,  352,  353,  354,  356,  357,\n",
       "          358,  359,  361,  362,  363,  364,  366,  367,  368,  369,  371,\n",
       "          372,  373,  375,  376,  377,  378,  379,  381,  382,  383,  385,\n",
       "          386,  387,  388,  389,  390,  393,  394,  395,  396,  398,  399,\n",
       "          400,  401,  403,  404,  405,  406,  408,  409,  410,  411,  413,\n",
       "          414,  415,  416,  418,  419,  420,  421,  423,  424,  425,  426,\n",
       "          428,  429,  430,  431,  433,  434,  435,  436,  438,  439,  440,\n",
       "          441,  443,  444,  445,  446,  447,  448,  449,  450,  452,  453,\n",
       "          454,  455,  457,  458,  459,  460,  462,  463,  464,  465,  467,\n",
       "          468,  470,  472,  473,  474,  475,  477,  478,  479,  480,  482,\n",
       "          483,  484,  485,  486,  487,  488,  489,  491,  492,  493,  494,\n",
       "          496,  497,  498,  499,  501,  502,  503,  504,  507,  508,  509,\n",
       "          510,  512,  513,  514,  515,  517,  518,  519,  520,  522,  523,\n",
       "          524,  525,  526,  527,  529,  531,  532,  533,  534,  536,  537,\n",
       "          538,  539,  541,  542,  543,  544,  545,  546,  547,  548,  549,\n",
       "          550,  551,  553,  554,  555,  556,  558,  559,  560,  561,  563,\n",
       "          564,  566,  567,  568,  569,  570,  572,  573,  574,  575,  576,\n",
       "          577,  578,  579,  580,  582,  583,  584,  586,  587,  588,  589,\n",
       "          590,  591,  593,  594,  595,  596,  598,  599,  600,  601,  604,\n",
       "          605,  606,  607,  608,  609,  610,  612,  613,  615,  617,  618,\n",
       "          619,  620,  622,  623,  624,  625,  626,  627,  628,  629,  631,\n",
       "          632,  633,  634,  636,  637,  638,  639,  641,  642,  644,  645,\n",
       "          646,  647,  648,  650,  651,  652,  653,  654,  655,  656,  657,\n",
       "          658,  660,  661,  662,  664,  665,  666,  667,  668,  669,  671,\n",
       "          672,  673,  674,  676,  677,  678,  679,  682,  683,  684,  685,\n",
       "          686,  687,  688,  690,  691,  693,  695,  696,  697,  698,  700,\n",
       "          701,  702,  703,  704,  705,  707,  708,  709,  710,  712,  713,\n",
       "          714,  715,  717,  718,  719,  720,  721,  722,  724,  726,  727,\n",
       "          728,  729,  731,  732,  733,  734,  736,  737,  738,  739,  740,\n",
       "          741,  743,  744,  745,  747,  748,  749,  750,  752,  753,  754,\n",
       "          755,  757,  758,  759,  760,  762,  763,  764,  766,  767,  768,\n",
       "          769,  770,  772,  773,  774,  776,  777,  778,  779,  781,  782,\n",
       "          783,  784,  786,  787,  788,  789,  791,  792,  793,  794,  796,\n",
       "          797,  798,  799,  801,  802,  803,  805,  806,  807,  808,  809,\n",
       "          811,  812,  813,  815,  816,  817,  818,  819,  820,  822,  823,\n",
       "          824,  826,  827,  828,  829,  831,  832,  833,  834,  836,  837,\n",
       "          839,  840,  841,  842,  843,  845,  846,  847,  848,  849,  850,\n",
       "          851,  852,  853,  855,  856,  859,  860,  862,  863,  864,  865,\n",
       "          867,  868,  869,  870,  872,  873,  874,  875,  876,  877,  878,\n",
       "          879,  881,  882,  883,  884,  886,  887,  888,  889,  891,  892,\n",
       "          893,  894,  897,  898,  899,  900,  902,  903,  904,  905,  907,\n",
       "          908,  909,  910,  912,  913,  914,  915,  916,  917,  919,  921,\n",
       "          922,  923,  924,  926,  927,  928,  929,  931,  932,  933,  934,\n",
       "          935,  936,  937,  940,  941,  942,  943,  945,  946,  947,  948,\n",
       "          950,  951,  952,  953,  954,  955,  956,  957,  959,  960,  961,\n",
       "          962,  964,  965,  966,  967,  969,  970,  971,  972,  975,  976,\n",
       "          977,  978,  980,  981,  982,  983,  985,  986,  987,  988,  990,\n",
       "          991,  992,  993,  994,  995,  997,  999, 1000, 1001, 1002, 1004,\n",
       "         1005, 1006, 1007, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016,\n",
       "         1017, 1018, 1019, 1020, 1022, 1023, 1025, 1027, 1028, 1029, 1030,\n",
       "         1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1042, 1043,\n",
       "         1045, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057,\n",
       "         1058, 1059, 1060, 1062, 1063, 1064, 1065, 1067, 1068, 1069, 1070,\n",
       "         1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1084, 1086,\n",
       "         1087, 1088, 1089, 1091, 1092, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "         1101, 1102, 1103, 1104, 1106, 1107, 1108, 1109, 1112, 1113, 1114,\n",
       "         1115, 1116, 1117, 1118, 1120, 1121, 1123, 1125, 1126, 1127, 1128,\n",
       "         1130, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1139, 1141, 1142,\n",
       "         1143, 1144, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1155,\n",
       "         1156, 1157, 1158, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168,\n",
       "         1170, 1171, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1182, 1183,\n",
       "         1184, 1185, 1187, 1188, 1189, 1190, 1192, 1193, 1194, 1196, 1197,\n",
       "         1198, 1199, 1200, 1202, 1203, 1204, 1206, 1207, 1208, 1209, 1210,\n",
       "         1211, 1213, 1214, 1215, 1217, 1218, 1219, 1220, 1222, 1223, 1224,\n",
       "         1225, 1227, 1228, 1230, 1231, 1232, 1233, 1234, 1236, 1237, 1238,\n",
       "         1239, 1240, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249]),\n",
       "  array([   4,    9,   14,   17,   23,   33,   37,   44,   49,   54,   55,\n",
       "           63,   66,   68,   73,   76,   81,   87,   91,   96,  101,  107,\n",
       "          111,  116,  121,  126,  131,  136,  140,  146,  150,  160,  165,\n",
       "          170,  175,  179,  185,  189,  196,  200,  205,  210,  213,  219,\n",
       "          229,  232,  233,  236,  241,  246,  255,  260,  265,  270,  271,\n",
       "          276,  281,  286,  293,  295,  300,  305,  311,  315,  320,  325,\n",
       "          332,  334,  339,  344,  351,  355,  360,  365,  370,  374,  380,\n",
       "          384,  391,  392,  397,  402,  407,  412,  417,  422,  427,  432,\n",
       "          437,  442,  451,  456,  461,  466,  469,  471,  476,  481,  490,\n",
       "          495,  500,  505,  506,  511,  516,  521,  528,  530,  535,  540,\n",
       "          552,  557,  562,  565,  571,  581,  585,  592,  597,  602,  603,\n",
       "          611,  614,  616,  621,  630,  635,  640,  643,  649,  659,  663,\n",
       "          670,  675,  680,  681,  689,  692,  694,  699,  706,  711,  716,\n",
       "          723,  725,  730,  735,  742,  746,  751,  756,  761,  765,  771,\n",
       "          775,  780,  785,  790,  795,  800,  804,  810,  814,  821,  825,\n",
       "          830,  835,  838,  844,  854,  857,  858,  861,  866,  871,  880,\n",
       "          885,  890,  895,  896,  901,  906,  911,  918,  920,  925,  930,\n",
       "          938,  939,  944,  949,  958,  963,  968,  973,  974,  979,  984,\n",
       "          989,  996,  998, 1003, 1008, 1021, 1024, 1026, 1031, 1041, 1044,\n",
       "         1046, 1051, 1061, 1066, 1071, 1072, 1080, 1083, 1085, 1090, 1093,\n",
       "         1100, 1105, 1110, 1111, 1119, 1122, 1124, 1129, 1135, 1140, 1145,\n",
       "         1154, 1159, 1164, 1169, 1172, 1176, 1181, 1186, 1191, 1195, 1201,\n",
       "         1205, 1212, 1216, 1221, 1226, 1229, 1235, 1245])],\n",
       " [array([   0,    1,    2,    3,    4,    6,    7,    8,    9,   11,   12,\n",
       "           13,   14,   17,   18,   19,   20,   21,   22,   23,   25,   26,\n",
       "           28,   30,   31,   32,   33,   35,   36,   37,   38,   39,   41,\n",
       "           42,   43,   44,   46,   47,   48,   49,   51,   52,   53,   54,\n",
       "           55,   56,   57,   58,   60,   61,   62,   63,   65,   66,   67,\n",
       "           68,   70,   71,   72,   73,   75,   76,   77,   78,   79,   80,\n",
       "           81,   83,   84,   85,   86,   87,   88,   89,   90,   91,   93,\n",
       "           94,   96,   98,   99,  100,  101,  103,  104,  105,  106,  107,\n",
       "          108,  109,  110,  111,  113,  114,  115,  116,  119,  120,  121,\n",
       "          123,  124,  125,  126,  128,  129,  130,  131,  133,  134,  136,\n",
       "          137,  138,  139,  140,  142,  143,  144,  145,  146,  147,  148,\n",
       "          149,  150,  152,  153,  155,  156,  158,  159,  160,  162,  163,\n",
       "          164,  165,  167,  168,  169,  170,  172,  173,  175,  176,  177,\n",
       "          178,  179,  181,  182,  183,  184,  185,  186,  187,  188,  189,\n",
       "          191,  192,  193,  195,  196,  197,  198,  199,  200,  202,  203,\n",
       "          204,  205,  207,  208,  209,  210,  213,  214,  215,  216,  217,\n",
       "          218,  219,  221,  222,  224,  226,  227,  228,  229,  231,  232,\n",
       "          233,  234,  235,  236,  238,  239,  240,  241,  243,  244,  245,\n",
       "          246,  248,  249,  250,  251,  252,  253,  255,  257,  258,  259,\n",
       "          260,  262,  263,  264,  265,  267,  268,  269,  270,  271,  272,\n",
       "          274,  275,  276,  278,  279,  280,  281,  283,  284,  285,  286,\n",
       "          288,  289,  290,  291,  293,  294,  295,  297,  298,  299,  300,\n",
       "          301,  303,  304,  305,  307,  308,  309,  311,  312,  313,  314,\n",
       "          315,  317,  318,  319,  320,  322,  323,  324,  325,  327,  328,\n",
       "          329,  330,  332,  333,  334,  336,  337,  338,  339,  340,  342,\n",
       "          343,  344,  346,  347,  348,  349,  350,  351,  353,  354,  355,\n",
       "          357,  358,  359,  360,  362,  363,  364,  365,  367,  368,  370,\n",
       "          371,  372,  373,  374,  376,  377,  378,  379,  380,  381,  382,\n",
       "          383,  384,  386,  387,  389,  391,  392,  394,  395,  396,  397,\n",
       "          399,  400,  401,  402,  404,  405,  406,  407,  408,  409,  410,\n",
       "          412,  414,  415,  416,  417,  419,  420,  421,  422,  424,  425,\n",
       "          426,  427,  429,  430,  431,  432,  434,  435,  436,  437,  439,\n",
       "          440,  441,  442,  444,  445,  446,  447,  448,  449,  451,  453,\n",
       "          454,  455,  456,  458,  459,  460,  461,  463,  464,  465,  466,\n",
       "          467,  468,  469,  470,  471,  473,  474,  475,  476,  478,  479,\n",
       "          480,  481,  483,  484,  485,  486,  487,  488,  490,  492,  493,\n",
       "          494,  495,  497,  498,  499,  500,  502,  503,  504,  505,  506,\n",
       "          507,  509,  510,  511,  513,  514,  515,  516,  518,  519,  520,\n",
       "          521,  523,  524,  525,  526,  528,  529,  530,  532,  533,  534,\n",
       "          535,  536,  538,  539,  540,  542,  543,  544,  545,  546,  547,\n",
       "          549,  550,  551,  552,  554,  555,  556,  557,  559,  560,  561,\n",
       "          562,  565,  566,  567,  568,  569,  570,  571,  573,  574,  576,\n",
       "          578,  579,  580,  581,  583,  584,  585,  586,  587,  589,  590,\n",
       "          591,  592,  594,  595,  596,  597,  599,  600,  601,  602,  603,\n",
       "          604,  605,  606,  608,  609,  610,  611,  613,  614,  615,  616,\n",
       "          618,  619,  620,  621,  623,  624,  625,  626,  627,  628,  629,\n",
       "          630,  632,  633,  634,  635,  637,  638,  639,  640,  643,  644,\n",
       "          645,  646,  647,  648,  649,  651,  652,  654,  656,  657,  658,\n",
       "          659,  661,  662,  663,  664,  665,  667,  668,  669,  670,  672,\n",
       "          673,  674,  675,  677,  678,  679,  680,  681,  682,  683,  684,\n",
       "          686,  687,  688,  689,  691,  692,  693,  694,  696,  697,  698,\n",
       "          699,  701,  702,  704,  705,  706,  708,  709,  710,  711,  713,\n",
       "          714,  715,  716,  718,  719,  720,  721,  723,  724,  725,  727,\n",
       "          728,  729,  730,  731,  733,  734,  735,  737,  738,  739,  740,\n",
       "          741,  742,  744,  745,  746,  748,  749,  750,  751,  753,  754,\n",
       "          755,  756,  758,  759,  761,  762,  763,  764,  765,  767,  768,\n",
       "          769,  770,  771,  772,  773,  774,  775,  777,  778,  780,  781,\n",
       "          783,  784,  785,  787,  788,  789,  790,  792,  793,  794,  795,\n",
       "          797,  798,  800,  801,  802,  803,  804,  806,  807,  808,  809,\n",
       "          810,  811,  812,  813,  814,  816,  817,  818,  820,  821,  822,\n",
       "          823,  824,  825,  827,  828,  829,  830,  832,  833,  834,  835,\n",
       "          838,  839,  840,  841,  842,  843,  844,  846,  847,  849,  851,\n",
       "          852,  853,  854,  856,  857,  858,  859,  860,  861,  863,  864,\n",
       "          865,  866,  868,  869,  870,  871,  873,  874,  875,  876,  877,\n",
       "          878,  880,  882,  883,  884,  885,  887,  888,  889,  890,  892,\n",
       "          893,  894,  895,  896,  897,  899,  900,  901,  903,  904,  905,\n",
       "          906,  908,  909,  910,  911,  913,  914,  915,  916,  918,  919,\n",
       "          920,  922,  923,  924,  925,  926,  928,  929,  930,  932,  933,\n",
       "          934,  935,  936,  938,  939,  941,  942,  943,  944,  946,  947,\n",
       "          948,  949,  951,  952,  953,  954,  955,  956,  958,  960,  961,\n",
       "          962,  963,  965,  966,  967,  968,  970,  971,  972,  973,  974,\n",
       "          975,  977,  978,  979,  981,  982,  983,  984,  986,  987,  988,\n",
       "          989,  991,  992,  993,  994,  996,  997,  998, 1000, 1001, 1002,\n",
       "         1003, 1004, 1006, 1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015,\n",
       "         1018, 1019, 1020, 1021, 1023, 1024, 1025, 1026, 1028, 1029, 1030,\n",
       "         1031, 1033, 1034, 1035, 1036, 1038, 1039, 1040, 1041, 1043, 1044,\n",
       "         1045, 1046, 1048, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1058,\n",
       "         1059, 1060, 1061, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071,\n",
       "         1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1082, 1083, 1084,\n",
       "         1085, 1087, 1088, 1089, 1090, 1092, 1093, 1095, 1097, 1098, 1099,\n",
       "         1100, 1102, 1103, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1112,\n",
       "         1113, 1114, 1116, 1117, 1118, 1119, 1121, 1122, 1123, 1124, 1126,\n",
       "         1127, 1128, 1129, 1132, 1133, 1134, 1135, 1137, 1138, 1139, 1140,\n",
       "         1142, 1143, 1144, 1145, 1147, 1148, 1149, 1150, 1151, 1152, 1154,\n",
       "         1156, 1157, 1158, 1159, 1161, 1162, 1163, 1164, 1166, 1167, 1168,\n",
       "         1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1178, 1179, 1180,\n",
       "         1181, 1183, 1184, 1185, 1186, 1188, 1189, 1191, 1192, 1193, 1194,\n",
       "         1195, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1207,\n",
       "         1208, 1209, 1211, 1212, 1213, 1214, 1215, 1216, 1218, 1219, 1220,\n",
       "         1221, 1223, 1224, 1225, 1226, 1229, 1230, 1231, 1232, 1233, 1234,\n",
       "         1235, 1237, 1238, 1240, 1242, 1243, 1244, 1245, 1247, 1249]),\n",
       "  array([   5,   10,   15,   16,   24,   27,   29,   34,   40,   45,   50,\n",
       "           59,   64,   69,   74,   82,   92,   95,   97,  102,  112,  117,\n",
       "          118,  122,  127,  132,  135,  141,  151,  154,  157,  161,  166,\n",
       "          171,  174,  180,  190,  194,  201,  206,  211,  212,  220,  223,\n",
       "          225,  230,  237,  242,  247,  254,  256,  261,  266,  273,  277,\n",
       "          282,  287,  292,  296,  302,  306,  310,  316,  321,  326,  331,\n",
       "          335,  341,  345,  352,  356,  361,  366,  369,  375,  385,  388,\n",
       "          390,  393,  398,  403,  411,  413,  418,  423,  428,  433,  438,\n",
       "          443,  450,  452,  457,  462,  472,  477,  482,  489,  491,  496,\n",
       "          501,  508,  512,  517,  522,  527,  531,  537,  541,  548,  553,\n",
       "          558,  563,  564,  572,  575,  577,  582,  588,  593,  598,  607,\n",
       "          612,  617,  622,  631,  636,  641,  642,  650,  653,  655,  660,\n",
       "          666,  671,  676,  685,  690,  695,  700,  703,  707,  712,  717,\n",
       "          722,  726,  732,  736,  743,  747,  752,  757,  760,  766,  776,\n",
       "          779,  782,  786,  791,  796,  799,  805,  815,  819,  826,  831,\n",
       "          836,  837,  845,  848,  850,  855,  862,  867,  872,  879,  881,\n",
       "          886,  891,  898,  902,  907,  912,  917,  921,  927,  931,  937,\n",
       "          940,  945,  950,  957,  959,  964,  969,  976,  980,  985,  990,\n",
       "          995,  999, 1005, 1009, 1016, 1017, 1022, 1027, 1032, 1037, 1042,\n",
       "         1047, 1052, 1057, 1062, 1067, 1076, 1081, 1086, 1091, 1094, 1096,\n",
       "         1101, 1106, 1115, 1120, 1125, 1130, 1131, 1136, 1141, 1146, 1153,\n",
       "         1155, 1160, 1165, 1177, 1182, 1187, 1190, 1196, 1206, 1210, 1217,\n",
       "         1222, 1227, 1228, 1236, 1239, 1241, 1246, 1248])],\n",
       " [array([   2,    3,    4,    5,    7,    8,    9,   10,   12,   13,   14,\n",
       "           15,   16,   17,   18,   19,   21,   22,   23,   24,   26,   27,\n",
       "           28,   29,   31,   32,   33,   34,   37,   38,   39,   40,   42,\n",
       "           43,   44,   45,   47,   48,   49,   50,   52,   53,   54,   55,\n",
       "           56,   57,   59,   61,   62,   63,   64,   66,   67,   68,   69,\n",
       "           71,   72,   73,   74,   75,   76,   77,   78,   79,   80,   81,\n",
       "           82,   84,   85,   87,   89,   90,   91,   92,   94,   95,   96,\n",
       "           97,   98,   99,  100,  101,  102,  104,  105,  107,  109,  110,\n",
       "          111,  112,  114,  115,  116,  117,  118,  119,  120,  121,  122,\n",
       "          124,  125,  126,  127,  129,  130,  131,  132,  135,  136,  137,\n",
       "          138,  139,  140,  141,  143,  144,  146,  148,  149,  150,  151,\n",
       "          153,  154,  156,  157,  158,  159,  160,  161,  163,  164,  165,\n",
       "          166,  168,  169,  170,  171,  174,  175,  176,  177,  178,  179,\n",
       "          180,  182,  183,  185,  187,  188,  189,  190,  192,  193,  194,\n",
       "          195,  196,  198,  199,  200,  201,  203,  204,  205,  206,  208,\n",
       "          209,  210,  211,  212,  213,  214,  215,  217,  218,  219,  220,\n",
       "          222,  223,  224,  225,  227,  228,  229,  230,  232,  233,  235,\n",
       "          236,  237,  239,  240,  241,  242,  244,  245,  246,  247,  249,\n",
       "          250,  251,  252,  254,  255,  256,  258,  259,  260,  261,  262,\n",
       "          264,  265,  266,  268,  269,  270,  271,  272,  273,  275,  276,\n",
       "          277,  279,  280,  281,  282,  284,  285,  286,  287,  289,  290,\n",
       "          292,  293,  294,  295,  296,  298,  299,  300,  301,  302,  303,\n",
       "          304,  305,  306,  308,  309,  310,  311,  312,  313,  314,  315,\n",
       "          316,  318,  319,  320,  321,  323,  324,  325,  326,  328,  329,\n",
       "          331,  332,  333,  334,  335,  337,  338,  339,  340,  341,  342,\n",
       "          343,  344,  345,  347,  348,  349,  351,  352,  353,  354,  355,\n",
       "          356,  358,  359,  360,  361,  363,  364,  365,  366,  369,  370,\n",
       "          371,  372,  373,  374,  375,  377,  378,  380,  382,  383,  384,\n",
       "          385,  387,  388,  390,  391,  392,  393,  395,  396,  397,  398,\n",
       "          399,  401,  402,  403,  405,  406,  407,  408,  410,  411,  412,\n",
       "          413,  415,  416,  417,  418,  419,  421,  422,  423,  425,  426,\n",
       "          427,  428,  430,  431,  432,  433,  435,  436,  437,  438,  440,\n",
       "          441,  442,  443,  445,  446,  447,  448,  450,  451,  452,  454,\n",
       "          455,  456,  457,  458,  460,  461,  462,  464,  465,  466,  467,\n",
       "          468,  469,  470,  471,  472,  474,  475,  476,  477,  479,  480,\n",
       "          481,  482,  484,  485,  486,  487,  489,  490,  491,  493,  494,\n",
       "          495,  496,  497,  499,  500,  501,  503,  504,  505,  506,  507,\n",
       "          508,  510,  511,  512,  514,  515,  516,  517,  519,  520,  521,\n",
       "          522,  524,  525,  527,  528,  529,  530,  531,  533,  534,  535,\n",
       "          536,  537,  538,  539,  540,  541,  543,  544,  547,  548,  550,\n",
       "          551,  552,  553,  555,  556,  557,  558,  560,  561,  562,  563,\n",
       "          564,  565,  566,  567,  569,  570,  571,  572,  574,  575,  576,\n",
       "          577,  579,  580,  581,  582,  585,  586,  587,  588,  590,  591,\n",
       "          592,  593,  595,  596,  597,  598,  600,  601,  602,  603,  604,\n",
       "          605,  607,  609,  610,  611,  612,  614,  615,  616,  617,  619,\n",
       "          620,  621,  622,  624,  625,  626,  628,  629,  630,  631,  633,\n",
       "          634,  635,  636,  638,  639,  640,  641,  642,  643,  644,  645,\n",
       "          647,  648,  649,  650,  652,  653,  654,  655,  657,  658,  659,\n",
       "          660,  663,  664,  665,  666,  668,  669,  670,  671,  673,  674,\n",
       "          675,  676,  678,  679,  680,  681,  682,  683,  685,  687,  688,\n",
       "          689,  690,  692,  693,  694,  695,  697,  698,  699,  700,  701,\n",
       "          702,  703,  704,  705,  706,  707,  709,  710,  711,  712,  714,\n",
       "          715,  716,  717,  719,  720,  722,  723,  724,  725,  726,  728,\n",
       "          729,  730,  731,  732,  733,  734,  735,  736,  738,  739,  740,\n",
       "          742,  743,  744,  745,  746,  747,  749,  750,  751,  752,  754,\n",
       "          755,  756,  757,  760,  761,  762,  763,  764,  765,  766,  768,\n",
       "          769,  771,  773,  774,  775,  776,  778,  779,  780,  782,  783,\n",
       "          784,  785,  786,  788,  789,  790,  791,  793,  794,  795,  796,\n",
       "          799,  800,  801,  802,  803,  804,  805,  807,  808,  810,  812,\n",
       "          813,  814,  815,  817,  818,  819,  820,  821,  823,  824,  825,\n",
       "          826,  828,  829,  830,  831,  833,  834,  835,  836,  837,  838,\n",
       "          839,  840,  842,  843,  844,  845,  847,  848,  849,  850,  852,\n",
       "          853,  854,  855,  857,  858,  860,  861,  862,  864,  865,  866,\n",
       "          867,  869,  870,  871,  872,  874,  875,  876,  877,  879,  880,\n",
       "          881,  883,  884,  885,  886,  887,  889,  890,  891,  893,  894,\n",
       "          895,  896,  897,  898,  900,  901,  902,  904,  905,  906,  907,\n",
       "          909,  910,  911,  912,  914,  915,  917,  918,  919,  920,  921,\n",
       "          923,  924,  925,  926,  927,  928,  929,  930,  931,  933,  934,\n",
       "          935,  937,  938,  939,  940,  942,  943,  944,  945,  947,  948,\n",
       "          949,  950,  952,  953,  954,  955,  957,  958,  959,  961,  962,\n",
       "          963,  964,  965,  967,  968,  969,  971,  972,  973,  974,  975,\n",
       "          976,  978,  979,  980,  982,  983,  984,  985,  987,  988,  989,\n",
       "          990,  992,  993,  995,  996,  997,  998,  999, 1001, 1002, 1003,\n",
       "         1004, 1005, 1006, 1007, 1008, 1009, 1011, 1012, 1014, 1016, 1017,\n",
       "         1019, 1020, 1021, 1022, 1024, 1025, 1026, 1027, 1029, 1030, 1031,\n",
       "         1032, 1033, 1034, 1035, 1037, 1039, 1040, 1041, 1042, 1044, 1045,\n",
       "         1046, 1047, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1059,\n",
       "         1060, 1061, 1062, 1064, 1065, 1066, 1067, 1069, 1070, 1071, 1072,\n",
       "         1073, 1074, 1076, 1078, 1079, 1080, 1081, 1083, 1084, 1085, 1086,\n",
       "         1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099,\n",
       "         1100, 1101, 1103, 1104, 1105, 1106, 1108, 1109, 1110, 1111, 1112,\n",
       "         1113, 1115, 1117, 1118, 1119, 1120, 1122, 1123, 1124, 1125, 1127,\n",
       "         1128, 1129, 1130, 1131, 1132, 1134, 1135, 1136, 1138, 1139, 1140,\n",
       "         1141, 1143, 1144, 1145, 1146, 1148, 1149, 1150, 1151, 1153, 1154,\n",
       "         1155, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1167, 1168,\n",
       "         1169, 1170, 1171, 1172, 1174, 1175, 1176, 1177, 1179, 1180, 1181,\n",
       "         1182, 1184, 1185, 1186, 1187, 1190, 1191, 1192, 1193, 1194, 1195,\n",
       "         1196, 1198, 1199, 1201, 1203, 1204, 1205, 1206, 1208, 1209, 1210,\n",
       "         1211, 1212, 1214, 1215, 1216, 1217, 1219, 1220, 1221, 1222, 1224,\n",
       "         1225, 1226, 1227, 1228, 1229, 1230, 1231, 1233, 1234, 1235, 1236,\n",
       "         1238, 1239, 1240, 1241, 1243, 1244, 1245, 1246, 1248, 1249]),\n",
       "  array([   0,    1,    6,   11,   20,   25,   30,   35,   36,   41,   46,\n",
       "           51,   58,   60,   65,   70,   83,   86,   88,   93,  103,  106,\n",
       "          108,  113,  123,  128,  133,  134,  142,  145,  147,  152,  155,\n",
       "          162,  167,  172,  173,  181,  184,  186,  191,  197,  202,  207,\n",
       "          216,  221,  226,  231,  234,  238,  243,  248,  253,  257,  263,\n",
       "          267,  274,  278,  283,  288,  291,  297,  307,  317,  322,  327,\n",
       "          330,  336,  346,  350,  357,  362,  367,  368,  376,  379,  381,\n",
       "          386,  389,  394,  400,  404,  409,  414,  420,  424,  429,  434,\n",
       "          439,  444,  449,  453,  459,  463,  473,  478,  483,  488,  492,\n",
       "          498,  502,  509,  513,  518,  523,  526,  532,  542,  545,  546,\n",
       "          549,  554,  559,  568,  573,  578,  583,  584,  589,  594,  599,\n",
       "          606,  608,  613,  618,  623,  627,  632,  637,  646,  651,  656,\n",
       "          661,  662,  667,  672,  677,  684,  686,  691,  696,  708,  713,\n",
       "          718,  721,  727,  737,  741,  748,  753,  758,  759,  767,  770,\n",
       "          772,  777,  781,  787,  792,  797,  798,  806,  809,  811,  816,\n",
       "          822,  827,  832,  841,  846,  851,  856,  859,  863,  868,  873,\n",
       "          878,  882,  888,  892,  899,  903,  908,  913,  916,  922,  932,\n",
       "          936,  941,  946,  951,  956,  960,  966,  970,  977,  981,  986,\n",
       "          991,  994, 1000, 1010, 1013, 1015, 1018, 1023, 1028, 1036, 1038,\n",
       "         1043, 1048, 1053, 1058, 1063, 1068, 1075, 1077, 1082, 1087, 1097,\n",
       "         1102, 1107, 1114, 1116, 1121, 1126, 1133, 1137, 1142, 1147, 1152,\n",
       "         1156, 1162, 1166, 1173, 1178, 1183, 1188, 1189, 1197, 1200, 1202,\n",
       "         1207, 1213, 1218, 1223, 1232, 1237, 1242, 1247])]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.9256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 13, 4000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim.lr_scheduler' has no attribute 'OneCycleLR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7f84c56afe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFocalLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, max_lr=0.001, epochs=no_of_epochs,\n\u001b[0m\u001b[1;32m    135\u001b[0m                                                 steps_per_epoch=len(train_dataloader))\n\u001b[1;32m    136\u001b[0m         \u001b[0mavg_train_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_valid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim.lr_scheduler' has no attribute 'OneCycleLR'"
     ]
    }
   ],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, checkpoint_path='checkpoint.pt', is_maximize=True):\n",
    "        self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "        self.counter, self.best_score = 0, None\n",
    "        self.is_maximize = is_maximize\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None or \\\n",
    "        (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)\n",
    "            self.best_score, self.counter = score, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "class Seq2SeqRnn(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, output_size, num_layers=1, bidirectional=False, dropout=.3,\n",
    "            hidden_layers = [100, 200]):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.bidirectional=bidirectional\n",
    "        self.output_size=output_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, batch_first=True,dropout=0.3)\n",
    "         # Input Layer\n",
    "        if hidden_layers and len(hidden_layers):\n",
    "            first_layer  = nn.Linear(hidden_size*2 if bidirectional else hidden_size, hidden_layers[0])\n",
    "\n",
    "            # Hidden Layers\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [first_layer]+[nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers) - 1)]\n",
    "            )\n",
    "            for layer in self.hidden_layers: nn.init.kaiming_normal_(layer.weight.data)   \n",
    "\n",
    "            self.intermediate_layer = nn.Linear(hidden_layers[-1], self.input_size)\n",
    "            # output layers\n",
    "            self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "           \n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "            self.intermediate_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_siz, self.input_size)\n",
    "            self.output_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_size, output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "\n",
    "        self.activation_fn = torch.relu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        outputs, hidden = self.rnn(x)        \n",
    "\n",
    "        x = self.dropout(self.activation_fn(outputs))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fn(hidden_layer(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class IonDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, training=True, transform=None, flip=0.5, noise_level=0, class_split=0.0):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "        self.flip = flip\n",
    "        self.noise_level = noise_level\n",
    "        self.class_split = class_split\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "        if np.random.rand() < self.class_split:\n",
    "            data, labels = class_split(data, labels)\n",
    "        if  np.random.rand() < self.noise_level:\n",
    "            data = data * torch.FloatTensor(10000).uniform_(1-self.noise_level, 1+self.noise_level)\n",
    "        if np.random.rand() < self.flip:\n",
    "            data = torch.flip(data, dims=[1])\n",
    "            labels = np.flip(labels, axis=0).copy().astype(int)\n",
    "\n",
    "        return [data, labels.astype(int)]\n",
    "\n",
    "if not os.path.exists(\"./models\"):\n",
    "            os.makedirs(\"./models\")\n",
    "for index, (train_index, val_index ) in enumerate(new_splits[0:], start=0):\n",
    "    print(\"Fold : {}\".format(index))\n",
    "    \n",
    "    batchsize = 16\n",
    "    train_dataset = IonDataset(trainval[train_index],  trainval_y[train_index], flip=False, noise_level=0.0, class_split=0.0)\n",
    "    train_dataloader = DataLoader(train_dataset, batchsize, shuffle=True)\n",
    "\n",
    "    valid_dataset = IonDataset(trainval[val_index],  trainval_y[val_index], flip=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batchsize, shuffle=False)\n",
    "\n",
    "    test_dataset = IonDataset(test,  test_y, flip=False, noise_level=0.0, class_split=0.0)\n",
    "    test_dataloader = DataLoader(test_dataset, batchsize, shuffle=False)\n",
    "    train_preds_iter = np.zeros((5000000, 11))\n",
    "    test_preds_iter = np.zeros((2000000, 11))\n",
    "    \n",
    "    it = 0\n",
    "    for it in range(1):\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model=Seq2SeqRnn(input_size=trainval.shape[1], seq_len=4000, hidden_size=64, output_size=11, num_layers=2, hidden_layers=[64,64,64],\n",
    "                         bidirectional=True).to(device)\n",
    "    \n",
    "        no_of_epochs = 200\n",
    "        early_stopping = EarlyStopping(patience=20, is_maximize=True, checkpoint_path=\"./models/gru_clean_checkpoint_fold_{}_iter_{}_noise.pt\".format(index, it))\n",
    "        criterion = L.FocalLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, max_lr=0.001, epochs=no_of_epochs,\n",
    "                                                steps_per_epoch=len(train_dataloader))\n",
    "        avg_train_losses, avg_valid_losses = [], [] \n",
    "    \n",
    "    \n",
    "        for epoch in range(no_of_epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            date_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "            log.write(f\"{date_time} Epoch: {epoch} ... \\n\")\n",
    "            log.write(f\"{date_time} learning_rate: {schedular.get_lr()[0]:.9f} ... \\n\")\n",
    "    \n",
    "            train_losses, valid_losses = [], []\n",
    "    \n",
    "            model.train() # prep model for training\n",
    "            train_preds, train_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "    \n",
    "            for x, y in train_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(x[:, :trainval.shape[1], :])\n",
    "    \n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                y_ = y.view(-1)\n",
    "    \n",
    "                loss = criterion(predictions_, y_)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                schedular.step()\n",
    "                # record training lossa\n",
    "                train_losses.append(loss.item())\n",
    "    \n",
    "                train_true = torch.cat([train_true, y_], 0)\n",
    "                train_preds = torch.cat([train_preds, predictions_], 0)\n",
    "\n",
    "            model.eval() # prep model for evaluation\n",
    "            val_preds, val_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_dataloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "    \n",
    "                    predictions = model(x[:,:trainval.shape[1],:])\n",
    "                    predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                    y_ = y.view(-1)\n",
    "    \n",
    "                    loss = criterion(predictions_, y_)\n",
    "                    valid_losses.append(loss.item())\n",
    "        \n",
    "                    val_true = torch.cat([val_true, y_], 0)\n",
    "                    val_preds = torch.cat([val_preds, predictions_], 0)\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            train_loss = np.average(train_losses)\n",
    "            valid_loss = np.average(valid_losses)\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "            \n",
    "            log.write(f\"{date_time} train_loss: {train_loss:.6f}, valid_loss: {valid_loss:.6f} \\n\")\n",
    "\n",
    "            train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "    \n",
    "            val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            \n",
    "            log.write(f\"{date_time} train_f1: {train_score:.6f}, valid_f1: {val_score:.6f} \\n\")\n",
    "            #print( \"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "    \n",
    "            if early_stopping(val_score, model):\n",
    "                log.write(f\"{date_time} Early Stopping ... \\n\")\n",
    "                log.write(f\"{date_time} Best Val Score: {early_stopping.best_score:.6f} \\n\")\n",
    "                #print(\"Early Stopping...\")\n",
    "                #print(\"Best Val Score: {:0.6f}\".format(early_stopping.best_score))\n",
    "                break\n",
    "    \n",
    "            #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            log.write(f\"{date_time} --- %s seconds ---: {time.time() - start_time} \\n\")\n",
    "            \n",
    "        model.load_state_dict(torch.load(\"./models/gru_clean_checkpoint_fold_{}_iter_{}_noise.pt\".format(index, it)))\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_list = []\n",
    "            for x, y in test_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                predictions = model(x[:,:trainval.shape[1],:])\n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "\n",
    "                pred_list.append(F.softmax(predictions_, dim=1).cpu().numpy())\n",
    "            test_preds = np.vstack(pred_list)\n",
    "       \n",
    "        test_preds_iter += test_preds\n",
    "        test_preds_all += test_preds\n",
    "        if not os.path.exists(\"./predictions/test\"):\n",
    "            os.makedirs(\"./predictions/test\")\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_iter_{}_raw_noise.npy'.format(index, it), arr=test_preds_iter)\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_raw_noise.npy'.format(index), arr=test_preds_all)\n",
    "\n",
    "test_preds_all = test_preds_all/np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"./gru_preds_noise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
